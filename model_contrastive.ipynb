{"cells":[{"cell_type":"markdown","metadata":{"id":"JC-p4CpT1_Lc"},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T05:12:51.017424Z","iopub.status.busy":"2024-04-16T05:12:51.016653Z","iopub.status.idle":"2024-04-16T05:12:51.028310Z","shell.execute_reply":"2024-04-16T05:12:51.027476Z","shell.execute_reply.started":"2024-04-16T05:12:51.017395Z"},"id":"gr9MjCphpOPx","trusted":true},"outputs":[],"source":["# where we will unpack data\n","# OUTPUT_FOLDER = \"/kaggle/working/\"\n","# DATA_FOLDER = \"/kaggle/input/solfune-satellite/\"\n","# TRAIN_DATA_FOLDER = DATA_FOLDER + 'train/'\n","\n","OUTPUT_FOLDER = \"/scratch/aakash_ks.iitr/dr-scnn/\"\n","DATA_FOLDER = \"/scratch/aakash_ks.iitr/data/diabetic-retinopathy/\"\n","TRAIN_DATA_FOLDER = DATA_FOLDER + 'resized_train/'\n","# TEST_DATA_FOLDER = DATA_FOLDER + 'test/'"]},{"cell_type":"markdown","metadata":{"id":"dOaKi5h92DBb"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:13:45.703815Z","iopub.status.busy":"2024-04-14T16:13:45.703112Z","iopub.status.idle":"2024-04-14T16:13:47.998744Z","shell.execute_reply":"2024-04-14T16:13:47.997755Z","shell.execute_reply.started":"2024-04-14T16:13:45.703785Z"},"id":"NNdj2cxdkpiv","trusted":true},"outputs":[],"source":["import os\n","import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm\n","\n","from PIL import Image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:13:48.000701Z","iopub.status.busy":"2024-04-14T16:13:48.000307Z","iopub.status.idle":"2024-04-14T16:13:55.723296Z","shell.execute_reply":"2024-04-14T16:13:55.722301Z","shell.execute_reply.started":"2024-04-14T16:13:48.000675Z"},"id":"7yoCqGCB2jIS","trusted":true},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","\n","from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n","from torchvision.transforms import v2\n","\n","import timm"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-16T05:18:58.885632Z","iopub.status.busy":"2024-04-16T05:18:58.884804Z","iopub.status.idle":"2024-04-16T05:18:58.891553Z","shell.execute_reply":"2024-04-16T05:18:58.890585Z","shell.execute_reply.started":"2024-04-16T05:18:58.885598Z"},"id":"8Ejzj4rDx_GK","trusted":true},"outputs":[],"source":["NUM_CLASSES = 5\n","\n","class CFG:\n","    seed = 42\n","    N_folds = 5\n","    train_folds = [0] # [0,1,2,3,4]\n","\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    apex=True # use half precision\n","\n","    # model_name = \"maxvit_tiny_tf_512\"\n","    model_name = \"resnet50.a1_in1k\"\n","    epochs = 5\n","    # weights =  torch.tensor([0.206119, 0.793881],dtype=torch.float32)\n","\n","    clip_val = 1000.\n","    batch_size = 64\n","    # gradient_accumulation_steps = 1\n","\n","    lr = 1e-4\n","    weight_decay=1e-2\n","    \n","    resolution = 224"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T15:23:54.468659Z","iopub.status.busy":"2024-04-14T15:23:54.468265Z","iopub.status.idle":"2024-04-14T15:24:25.601196Z","shell.execute_reply":"2024-04-14T15:24:25.600218Z","shell.execute_reply.started":"2024-04-14T15:23:54.468630Z"},"trusted":true},"outputs":[],"source":["import wandb\n","# from kaggle_secrets import UserSecretsClient\n","# user_secrets = UserSecretsClient()\n","# wandb.login(key=user_secrets.get_secret(\"wandb_api\"))\n","\n","run = wandb.init(\n","    project=\"hello-world\", \n","    dir=OUTPUT_FOLDER,\n","    config={\n","    k:v for k, v in CFG.__dict__.items() if not k.startswith('__')}\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device(CFG.device)"]},{"cell_type":"markdown","metadata":{"id":"7Ve34id2b7uu"},"source":["# Load train data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:13:55.725554Z","iopub.status.busy":"2024-04-14T16:13:55.725188Z","iopub.status.idle":"2024-04-14T16:13:55.745976Z","shell.execute_reply":"2024-04-14T16:13:55.744974Z","shell.execute_reply.started":"2024-04-14T16:13:55.725520Z"},"id":"mq-oqFtvkpix","trusted":true},"outputs":[],"source":["train_data = pd.read_csv(os.path.join(DATA_FOLDER, 'trainLabels.csv'))\n","train_data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# remove all images from the csv if they are not in the folder\n","lst = map(lambda x: x[:-5], os.listdir(TRAIN_DATA_FOLDER))\n","train_data = train_data[train_data.image.isin(lst)]\n","len(train_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_data.level.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# take only 100 samples from each class\n","train_data = train_data.groupby('level').head(100).reset_index(drop=True)\n","train_data.level.value_counts()"]},{"cell_type":"markdown","metadata":{"id":"1Mu24W3Xkpix"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torchvision.transforms import functional as func\n","\n","class CustomTransform:\n","    def __init__(self, output_size=(CFG.resolution, CFG.resolution), radius_factor=0.9):\n","        self.output_size = output_size\n","        self.radius_factor = radius_factor\n","\n","    def __call__(self, img):\n","        # Assuming img is a PIL Image\n","        # Normalize and preprocess as previously defined\n","        img = func.resize(img, int(min(img.size) / self.radius_factor))\n","        img_tensor = func.to_tensor(img)\n","        mean, std = img_tensor.mean([1, 2]), img_tensor.std([1, 2])\n","        img_normalized = func.normalize(img_tensor, mean.tolist(), std.tolist())\n","        kernel_size = 15\n","        padding = kernel_size // 2\n","        avg_pool = torch.nn.AvgPool2d(kernel_size, stride=1, padding=padding)\n","        local_avg = avg_pool(img_normalized.unsqueeze(0)).squeeze(0)\n","        img_subtracted = img_normalized - local_avg\n","        center_crop_size = int(min(img_subtracted.shape[1:]) * self.radius_factor)\n","        img_cropped = func.center_crop(img_subtracted, [center_crop_size, center_crop_size])\n","\n","        # Apply augmentations\n","        img_resized = func.resize(img_cropped, self.output_size)\n","\n","        return img_resized"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:14:03.100814Z","iopub.status.busy":"2024-04-14T16:14:03.100062Z","iopub.status.idle":"2024-04-14T16:14:03.108402Z","shell.execute_reply":"2024-04-14T16:14:03.107471Z","shell.execute_reply.started":"2024-04-14T16:14:03.100781Z"},"trusted":true},"outputs":[],"source":["# train_transforms = CustomTransform()\n","\n","train_transforms = v2.Compose([\n","    CustomTransform(),\n","    v2.RandomResizedCrop(CFG.resolution, scale=(0.8, 1.0)),  # Krizhevsky style random cropping\n","    v2.RandomHorizontalFlip(),  # Random horizontal flip\n","    v2.RandomVerticalFlip(),  # Random vertical flip\n","    v2.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2)),  # Gaussian blur with random kernel size and sigma\n","    v2.RandomRotation(degrees=(0, 90)),  # Random rotation between 0 and 360 degrees\n","    v2.ToDtype(torch.float32, scale=False),\n","])\n","\n","val_transforms = v2.Compose([\n","    CustomTransform(),\n","    v2.ToDtype(torch.float32, scale=False),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:34.766966Z","iopub.status.busy":"2024-04-14T16:21:34.766584Z","iopub.status.idle":"2024-04-14T16:21:34.774717Z","shell.execute_reply":"2024-04-14T16:21:34.773808Z","shell.execute_reply.started":"2024-04-14T16:21:34.766935Z"},"id":"_mAcIdn2kpiy","scrolled":true,"trusted":true},"outputs":[],"source":["class ImageTrainDataset(Dataset):\n","    def __init__(\n","        self,\n","        folder,\n","        data,\n","        transforms,\n","    ):\n","        self.folder = folder\n","        self.data = data\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        d = self.data.loc[index]\n","        image = Image.open(f\"{self.folder}{d.image}.jpeg\")\n","        image = self.transforms(image)\n","        label = d.level\n","\n","        return image, torch.tensor(label, dtype=torch.long)"]},{"cell_type":"markdown","metadata":{"id":"OzgB1JpAv3qg"},"source":["# Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:35.486917Z","iopub.status.busy":"2024-04-14T16:21:35.486197Z","iopub.status.idle":"2024-04-14T16:21:35.493226Z","shell.execute_reply":"2024-04-14T16:21:35.492187Z","shell.execute_reply.started":"2024-04-14T16:21:35.486887Z"},"id":"n0u9VgXTv7VU","trusted":true},"outputs":[],"source":["def contrastive_loss(embeddings, labels, margin=1.0):\n","    distance_matrix = torch.cdist(embeddings, embeddings, p=2)  # Compute pairwise Euclidean distances\n","    matches = labels.unsqueeze(0) == labels.unsqueeze(1)  # Matrix where True indicates matching labels\n","    non_matches = ~matches\n","    \n","    # Select positive and negative pairs\n","    positive_distances = distance_matrix[matches].clamp(min=0.00001)  # Clamp to avoid sqrt of zero\n","    negative_distances = distance_matrix[non_matches].clamp(min=0.00001)\n","    \n","    # Calculate losses for all positives and negative pair combinations\n","    positive_loss = torch.mean(positive_distances)\n","    negative_loss = torch.mean(torch.relu(margin - negative_distances))\n","    \n","    # Total loss combines positive and negative contributions\n","    loss = positive_loss + negative_loss\n","    return loss"]},{"cell_type":"markdown","metadata":{"id":"Zyfw9PLdkpiz"},"source":["# Train and evaluate functions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class style:\n","    BLUE = '\\033[94m'\n","    GREEN = '\\033[92m'\n","    YELLOW = '\\033[93m'\n","    END = '\\033[0m'\n","    BOLD = '\\033[1m'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:36.151872Z","iopub.status.busy":"2024-04-14T16:21:36.151533Z","iopub.status.idle":"2024-04-14T16:21:36.156966Z","shell.execute_reply":"2024-04-14T16:21:36.155985Z","shell.execute_reply.started":"2024-04-14T16:21:36.151847Z"},"id":"KKt67LPn9YtB","trusted":true},"outputs":[],"source":["def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:36.353134Z","iopub.status.busy":"2024-04-14T16:21:36.352777Z","iopub.status.idle":"2024-04-14T16:21:36.363087Z","shell.execute_reply":"2024-04-14T16:21:36.362142Z","shell.execute_reply.started":"2024-04-14T16:21:36.353107Z"},"id":"yXcFJ6IYkpiz","trusted":true},"outputs":[],"source":["def evaluate_model(cfg, model, data_loader, loss_criterion, epoch=-1):\n","    # loss_fn = nn.CrossEntropyLoss(weight=cfg.weights.to(device), label_smoothing=0.1)\n","    loss_fn = loss_criterion\n","\n","    model.eval()\n","    val_loss = 0\n","\n","    targets = []\n","    predictions = []\n","\n","    total_len = len(data_loader)\n","    tk0 = tqdm(enumerate(data_loader), total=total_len)\n","    for step, (images, labels) in tk0:\n","        images = images.to(device)\n","        target = labels.to(device)\n","\n","        with torch.no_grad():\n","            ####################\n","            embeddings = model(images)\n","            loss = loss_fn(embeddings, target)\n","            ####################\n","\n","        val_loss += loss.item()\n","\n","        targets.append(target.detach().cpu())\n","        # predictions.append(logits.detach().cpu())\n","        del images, target, logits\n","\n","    targets = torch.cat(targets, dim=0)\n","    # predictions = torch.cat(predictions, dim=0)\n","    # predictions = F.sigmoid(predictions)\n","\n","    val_loss /= total_len\n","    # base_score, best_score, best_th = find_best_threshold(targets, predictions[:, 1])\n","    # roc_auc = roc_auc_score(targets.numpy(), predictions[:, 1].numpy())\n","    roc_auc = 1\n","\n","    print(f'Epoch {epoch} validation loss = {val_loss:.4f} auc = {roc_auc:.4f}')\n","    return val_loss, roc_auc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:36.532561Z","iopub.status.busy":"2024-04-14T16:21:36.532193Z","iopub.status.idle":"2024-04-14T16:21:36.545367Z","shell.execute_reply":"2024-04-14T16:21:36.544346Z","shell.execute_reply.started":"2024-04-14T16:21:36.532533Z"},"id":"nZFniP2hkpi0","trusted":true},"outputs":[],"source":["def train_epoch(cfg, model, train_loader, loss_criterion, optimizer, scheduler, epoch):\n","    scaler = torch.cuda.amp.GradScaler(enabled=cfg.apex)\n","    # loss_fn = nn.CrossEntropyLoss(weight=cfg.weights.to(device), label_smoothing=0.1)\n","    loss_fn = loss_criterion\n","\n","    model.train()\n","    train_loss = 0\n","    learning_rate_history = []\n","\n","    targets = []\n","    predictions = []\n","\n","    total_len = len(train_loader)\n","    tk0 = tqdm(enumerate(train_loader), total=total_len)\n","    for step, (images, labels) in tk0:\n","        images = images.to(device)\n","        target = labels.to(device)\n","\n","        # https://pytorch.org/blog/accelerating-training-on-nvidia-gpus-with-pytorch-automatic-mixed-precision/\n","        with torch.cuda.amp.autocast(enabled=cfg.apex):\n","            ####################\n","            embeddings = model(images)\n","            loss = loss_fn(embeddings, target)\n","            ####################\n","\n","        scaler.scale(loss).backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=cfg.clip_val)\n","\n","        train_loss += loss.item()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        optimizer.zero_grad()\n","\n","        if scheduler is None:\n","            lr = optimizer.param_groups[0]['lr']\n","        else:\n","            scheduler.step()\n","            lr = scheduler.get_last_lr()[0]\n","\n","        tk0.set_description(f\"Epoch {epoch} training {step+1}/{total_len} [LR {lr:0.6f}] - loss: {train_loss/(step+1):.4f}\")\n","        learning_rate_history.append(lr)\n","\n","        # targets.append(target.detach().cpu())\n","        # predictions.append(embeddings.detach().cpu())\n","        del images, target\n","\n","    # targets = torch.cat(targets, dim=0)\n","    # predictions = torch.cat(predictions, dim=0)\n","    # predictions = F.sigmoid(predictions)\n","\n","    train_loss /= total_len\n","    # roc_auc = roc_auc_score(targets.numpy(), predictions[:, 1].numpy())\n","    roc_auc = 1\n","\n","    print(f'Epoch {epoch} train loss = {train_loss:.4f}, auc = {roc_auc:.4f}')\n","    return train_loss, learning_rate_history, roc_auc"]},{"cell_type":"markdown","metadata":{"id":"qN83vJk4xCA3"},"source":["# Train model"]},{"cell_type":"markdown","metadata":{"id":"8NyHYtzwZT8h"},"source":["## Split data\n","\n","The distribution of classes in the training data is not balance so using StratifiedKFold will ensure that the distrubution of positive and negative samples in all folds will match the original distributions."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:39.039930Z","iopub.status.busy":"2024-04-14T16:21:39.039564Z","iopub.status.idle":"2024-04-14T16:21:39.307011Z","shell.execute_reply":"2024-04-14T16:21:39.306082Z","shell.execute_reply.started":"2024-04-14T16:21:39.039904Z"},"id":"HaYXa749AEes","outputId":"65b6c941-0e6e-4503-b513-574264d657ce","trusted":true},"outputs":[],"source":["# plt.figure(figsize=(4,2))\n","# sns.histplot(train_data[\"label\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:39.309571Z","iopub.status.busy":"2024-04-14T16:21:39.308889Z","iopub.status.idle":"2024-04-14T16:21:39.321211Z","shell.execute_reply":"2024-04-14T16:21:39.320264Z","shell.execute_reply.started":"2024-04-14T16:21:39.309534Z"},"id":"DRHeo8pr56FX","trusted":true},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","\n","sgkf = StratifiedKFold(n_splits=CFG.N_folds, random_state=CFG.seed, shuffle=True)\n","for i, (train_index, test_index) in enumerate(sgkf.split(train_data[\"image\"].values, train_data[\"level\"].values)):\n","    train_data.loc[test_index, \"fold\"] = i"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:39.448281Z","iopub.status.busy":"2024-04-14T16:21:39.447697Z","iopub.status.idle":"2024-04-14T16:21:39.484233Z","shell.execute_reply":"2024-04-14T16:21:39.483014Z","shell.execute_reply.started":"2024-04-14T16:21:39.448249Z"},"trusted":true},"outputs":[],"source":["# from torchgeo import models\n","# from torch import nn"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:40.091094Z","iopub.status.busy":"2024-04-14T16:21:40.090402Z","iopub.status.idle":"2024-04-14T16:21:40.096027Z","shell.execute_reply":"2024-04-14T16:21:40.095120Z","shell.execute_reply.started":"2024-04-14T16:21:40.091064Z"},"trusted":true},"outputs":[],"source":["def create_model():\n","    ######################\n","    model = timm.create_model(CFG.model_name, num_classes=0)\n","    ######################\n","    \n","    # remove the last layer\n","#     model.fc = nn.Linear(in_features=2048, out_features=2, bias=True)\n","\n","    return model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"rF9BFqS8AXBY"},"source":["## Train folds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T16:21:40.983908Z","iopub.status.busy":"2024-04-14T16:21:40.983523Z","iopub.status.idle":"2024-04-14T16:21:48.524465Z","shell.execute_reply":"2024-04-14T16:21:48.523002Z","shell.execute_reply.started":"2024-04-14T16:21:40.983878Z"},"id":"7CFfmp3CxDG5","outputId":"952103d3-bbd9-449f-e9cf-26d5c2608aea","scrolled":true,"trusted":true},"outputs":[],"source":["for FOLD in CFG.train_folds:\n","\n","    seed_everything(CFG.seed)\n","\n","    # PREPARE DATA\n","    fold_train_data = train_data[train_data[\"fold\"] != FOLD].reset_index(drop=True)\n","    fold_valid_data = train_data[train_data[\"fold\"] == FOLD].reset_index(drop=True)\n","\n","    # display(\n","    #     pd.merge(\n","    #         fold_valid_data.groupby(by=[\"label\"])[\"file_name\"].count().rename(\"valid\").reset_index(),\n","    #         fold_train_data.groupby(by=[\"label\"])[\"file_name\"].count().rename(\"train\").reset_index(),\n","    #          on=\"label\", how=\"left\").T,)\n","\n","\n","    train_dataset = ImageTrainDataset(TRAIN_DATA_FOLDER, fold_train_data, transforms=train_transforms)\n","    valid_dataset = ImageTrainDataset(TRAIN_DATA_FOLDER, fold_valid_data, transforms=val_transforms)\n","\n","    train_loader = DataLoader(\n","            train_dataset,\n","            batch_size=CFG.batch_size,\n","            shuffle=True,\n","            num_workers=os.cpu_count(),\n","            pin_memory=True,\n","            drop_last=True\n","        )\n","\n","    valid_loader = DataLoader(\n","        valid_dataset,\n","        batch_size=CFG.batch_size,\n","        shuffle=False,\n","        num_workers=os.cpu_count(),\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","\n","    # PREPARE MODEL, OPTIMIZER AND SCHEDULER\n","    model = create_model()\n","    print(f\"Model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):_}\")\n","\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n","        optimizer, eta_min=1e-6, T_max =CFG.epochs * len(train_loader),\n","        )\n","    \n","    loss_criterion = contrastive_loss\n","\n","    # TRAIN FOLD\n","    learning_rate_history = []\n","    train_loss_history = []\n","    train_score_history = []\n","    val_loss_history = []\n","    val_score_history = []\n","\n","    best_score = 0\n","    \n","    wandb.run.tags = [f\"fold_{FOLD}\"]\n","    \n","    for epoch in range(0, CFG.epochs):\n","        train_loss, train_lr, train_auc = train_epoch(CFG, model, train_loader, loss_criterion, optimizer, scheduler, epoch)\n","        train_loss_history.append(train_loss)\n","        train_score_history.append(train_auc)\n","        learning_rate_history.extend(train_lr)\n","\n","        val_loss, val_auc = evaluate_model(CFG, model, valid_loader, loss_criterion, epoch)\n","        val_loss_history.append(val_loss)\n","        val_score_history.append(val_auc)\n","        \n","        wandb.log(\n","            {'train': {'loss': train_loss, 'auc': train_auc}, \n","             'val': {'loss': val_loss, 'auc': val_auc}})\n","\n","        if (val_auc >= best_score):\n","            print(f\"{style.GREEN}New best score: {best_score:.4f} -> {val_auc:.4f}{style.END}\")\n","            best_score = val_auc\n","            torch.save(model.state_dict(), os.path.join(wandb.run.dir, f'best_model_fold_{FOLD}.pth'))\n","            \n","    # run.log_model(\n","    #     path=os.path.join(wandb.run.dir, 'best_model_fold_{FOLD}'), \n","    #     name=f'{CFG.model_name}_fold_{FOLD}'\n","    # )\n","\n","    # # plot train and validation loss, score and LR\n","    # fig, axes = plt.subplots(1,3, figsize=(12,3))\n","    # axes[0].plot(train_loss_history, label=\"Train\")\n","    # axes[0].plot(val_loss_history, label=\"Valid\")\n","    # axes[0].title.set_text(\"Loss\")\n","    # axes[0].set_xlabel(\"Epoch\")\n","    # axes[0].legend()\n","\n","    # axes[1].plot(train_score_history, label=\"Train\")\n","    # axes[1].plot(val_score_history, label=\"Valid\")\n","    # axes[1].title.set_text(\"F1 score\")\n","    # axes[1].set_xlabel(\"Epoch\")\n","    # axes[1].legend()\n","\n","    # axes[2].plot(learning_rate_history, label=\"LR\")\n","    # axes[2].legend()\n","    # axes[2].title.set_text(\"Learning rate\")\n","    # axes[2].set_xlabel(\"Step\")\n","    # fig.suptitle(f\"Fold {FOLD}\")\n","    # fig.tight_layout()\n","    # plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4568125,"sourceId":7801430,"sourceType":"datasetVersion"},{"datasetId":4568781,"sourceId":7877494,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"08d2c86ce4ab4b9e813473170145d4af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96fb1b36ead648c4a4ebebb74c9fcf2c","placeholder":"​","style":"IPY_MODEL_af10206931434c6fbfde31af25affbfa","value":"model.safetensors: 100%"}},"103798aed0c64914b55a691a4d22253e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4420cb88a6a74540a671a529e7320589","placeholder":"​","style":"IPY_MODEL_6b7cb0c6580d4caba2c4f8385749a145","value":" 124M/124M [00:00&lt;00:00, 384MB/s]"}},"2831af4d288b45b688ba9b5992dce3f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3763df1b6564f319afc8d67073af72f","max":124450218,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4c3f492a9b946a0b72df7ea6bb188a9","value":124450218}},"4420cb88a6a74540a671a529e7320589":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b7cb0c6580d4caba2c4f8385749a145":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87901707be784b03998e8b8093255ea6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96fb1b36ead648c4a4ebebb74c9fcf2c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3763df1b6564f319afc8d67073af72f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4c3f492a9b946a0b72df7ea6bb188a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"af10206931434c6fbfde31af25affbfa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b53d0ba4ae3e496092fdf021cb4097aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08d2c86ce4ab4b9e813473170145d4af","IPY_MODEL_2831af4d288b45b688ba9b5992dce3f4","IPY_MODEL_103798aed0c64914b55a691a4d22253e"],"layout":"IPY_MODEL_87901707be784b03998e8b8093255ea6"}}}}},"nbformat":4,"nbformat_minor":4}
