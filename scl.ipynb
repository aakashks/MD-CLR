{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21c61999",
   "metadata": {
    "id": "JC-p4CpT1_Lc",
    "papermill": {
     "duration": 0.018629,
     "end_time": "2024-05-12T21:22:40.666822",
     "exception": false,
     "start_time": "2024-05-12T21:22:40.648193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ef689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:40.698540Z",
     "iopub.status.busy": "2024-05-12T21:22:40.698028Z",
     "iopub.status.idle": "2024-05-12T21:22:40.708628Z",
     "shell.execute_reply": "2024-05-12T21:22:40.707614Z"
    },
    "id": "gr9MjCphpOPx",
    "papermill": {
     "duration": 0.028325,
     "end_time": "2024-05-12T21:22:40.711081",
     "exception": false,
     "start_time": "2024-05-12T21:22:40.682756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = \"/scratch/aakash_ks.iitr/dr-scnn/\"\n",
    "DATA_FOLDER = \"/scratch/aakash_ks.iitr/data/diabetic-retinopathy/\"\n",
    "# TRAIN_DATA_FOLDER = DATA_FOLDER + 'resized_train/'\n",
    "TRAIN_DATA_FOLDER = DATA_FOLDER + 'resized_train_c/'\n",
    "\n",
    "# TEST_DATA_FOLDER = DATA_FOLDER + 'test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29b0bb",
   "metadata": {
    "id": "dOaKi5h92DBb",
    "papermill": {
     "duration": 0.019331,
     "end_time": "2024-05-12T21:22:40.742973",
     "exception": false,
     "start_time": "2024-05-12T21:22:40.723642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f05a740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:40.765383Z",
     "iopub.status.busy": "2024-05-12T21:22:40.764962Z",
     "iopub.status.idle": "2024-05-12T21:22:42.349769Z",
     "shell.execute_reply": "2024-05-12T21:22:42.349305Z"
    },
    "id": "NNdj2cxdkpiv",
    "papermill": {
     "duration": 1.597351,
     "end_time": "2024-05-12T21:22:42.351075",
     "exception": false,
     "start_time": "2024-05-12T21:22:40.753724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a002cee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:42.364315Z",
     "iopub.status.busy": "2024-05-12T21:22:42.363967Z",
     "iopub.status.idle": "2024-05-12T21:22:47.970752Z",
     "shell.execute_reply": "2024-05-12T21:22:47.970179Z"
    },
    "id": "7yoCqGCB2jIS",
    "papermill": {
     "duration": 5.614888,
     "end_time": "2024-05-12T21:22:47.972122",
     "exception": false,
     "start_time": "2024-05-12T21:22:42.357234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95612ee3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:47.985610Z",
     "iopub.status.busy": "2024-05-12T21:22:47.985123Z",
     "iopub.status.idle": "2024-05-12T21:22:48.018183Z",
     "shell.execute_reply": "2024-05-12T21:22:48.017589Z"
    },
    "id": "8Ejzj4rDx_GK",
    "papermill": {
     "duration": 0.040846,
     "end_time": "2024-05-12T21:22:48.019278",
     "exception": false,
     "start_time": "2024-05-12T21:22:47.978432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5\n",
    "\n",
    "class CFG:\n",
    "    seed = 42\n",
    "    N_folds = 5\n",
    "    train_folds = [0] # [0,1,2,3,4]\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    apex=True # use half precision\n",
    "    workers = 16\n",
    "\n",
    "    model_name = \"resnet50.a1_in1k\"\n",
    "    epochs = 21\n",
    "    cropped = True\n",
    "    # weights =  torch.tensor([0.206119, 0.793881],dtype=torch.float32)\n",
    "\n",
    "    clip_val = 1000.\n",
    "    batch_size = 64\n",
    "    # gradient_accumulation_steps = 1\n",
    "\n",
    "    lr = 2e-3\n",
    "    weight_decay=1e-2\n",
    "    \n",
    "    resolution = 224\n",
    "    samples_per_class = 1500\n",
    "    frozen_layers = 0\n",
    "    \n",
    "    cl_method = 'SupCon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c667e861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:48.044588Z",
     "iopub.status.busy": "2024-05-12T21:22:48.044327Z",
     "iopub.status.idle": "2024-05-12T21:22:56.142987Z",
     "shell.execute_reply": "2024-05-12T21:22:56.142482Z"
    },
    "papermill": {
     "duration": 8.119114,
     "end_time": "2024-05-12T21:22:56.144311",
     "exception": false,
     "start_time": "2024-05-12T21:22:48.025197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# wandb.login(key=user_secrets.get_secret(\"wandb_api\"))\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"aml\", \n",
    "    dir=OUTPUT_FOLDER,\n",
    "    config={\n",
    "    k:v for k, v in CFG.__dict__.items() if not k.startswith('__')}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17674522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import ctypes\n",
    "\n",
    "def clean_memory():\n",
    "    gc.collect()\n",
    "    ctypes.CDLL(\"libc.so.6\").malloc_trim(0)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "clean_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925a1e35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:56.171865Z",
     "iopub.status.busy": "2024-05-12T21:22:56.171523Z",
     "iopub.status.idle": "2024-05-12T21:22:56.174468Z",
     "shell.execute_reply": "2024-05-12T21:22:56.174054Z"
    },
    "papermill": {
     "duration": 0.024283,
     "end_time": "2024-05-12T21:22:56.175367",
     "exception": false,
     "start_time": "2024-05-12T21:22:56.151084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(CFG.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba249d",
   "metadata": {
    "id": "7Ve34id2b7uu",
    "papermill": {
     "duration": 0.011947,
     "end_time": "2024-05-12T21:22:56.205347",
     "exception": false,
     "start_time": "2024-05-12T21:22:56.193400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce91593",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:56.228062Z",
     "iopub.status.busy": "2024-05-12T21:22:56.227753Z",
     "iopub.status.idle": "2024-05-12T21:22:56.326401Z",
     "shell.execute_reply": "2024-05-12T21:22:56.325978Z"
    },
    "id": "mq-oqFtvkpix",
    "papermill": {
     "duration": 0.1066,
     "end_time": "2024-05-12T21:22:56.327351",
     "exception": false,
     "start_time": "2024-05-12T21:22:56.220751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv(os.path.join(DATA_FOLDER, 'trainLabels.csv'))\n",
    "train_data = pd.read_csv(os.path.join(DATA_FOLDER, 'trainLabels_cropped.csv')).sample(frac=1).reset_index(drop=True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a6ccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:56.353899Z",
     "iopub.status.busy": "2024-05-12T21:22:56.353569Z",
     "iopub.status.idle": "2024-05-12T21:22:56.402057Z",
     "shell.execute_reply": "2024-05-12T21:22:56.401584Z"
    },
    "papermill": {
     "duration": 0.069142,
     "end_time": "2024-05-12T21:22:56.403195",
     "exception": false,
     "start_time": "2024-05-12T21:22:56.334053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove all images from the csv if they are not in the folder\n",
    "lst = map(lambda x: x[:-5], os.listdir(TRAIN_DATA_FOLDER))\n",
    "train_data = train_data[train_data.image.isin(lst)]\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a54324e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:56.428925Z",
     "iopub.status.busy": "2024-05-12T21:22:56.428611Z",
     "iopub.status.idle": "2024-05-12T21:22:56.434068Z",
     "shell.execute_reply": "2024-05-12T21:22:56.433664Z"
    },
    "papermill": {
     "duration": 0.025159,
     "end_time": "2024-05-12T21:22:56.435047",
     "exception": false,
     "start_time": "2024-05-12T21:22:56.409888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6b1d6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:56.461906Z",
     "iopub.status.busy": "2024-05-12T21:22:56.461588Z",
     "iopub.status.idle": "2024-05-12T21:22:56.468855Z",
     "shell.execute_reply": "2024-05-12T21:22:56.468423Z"
    },
    "papermill": {
     "duration": 0.027832,
     "end_time": "2024-05-12T21:22:56.469770",
     "exception": false,
     "start_time": "2024-05-12T21:22:56.441938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# take only 100 samples from each class\n",
    "train_data = train_data.groupby('level').head(CFG.samples_per_class).reset_index(drop=True)\n",
    "train_data.level.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f1cb3",
   "metadata": {
    "id": "1Mu24W3Xkpix",
    "papermill": {
     "duration": 0.019387,
     "end_time": "2024-05-12T21:22:56.495732",
     "exception": false,
     "start_time": "2024-05-12T21:22:56.476345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c79b41f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:56.522078Z",
     "iopub.status.busy": "2024-05-12T21:22:56.521736Z",
     "iopub.status.idle": "2024-05-12T21:22:56.527460Z",
     "shell.execute_reply": "2024-05-12T21:22:56.526883Z"
    },
    "papermill": {
     "duration": 0.025963,
     "end_time": "2024-05-12T21:22:56.528355",
     "exception": false,
     "start_time": "2024-05-12T21:22:56.502392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import functional as func\n",
    "\n",
    "class CustomTransform:\n",
    "    def __init__(self, output_size=(CFG.resolution, CFG.resolution), radius_factor=0.9):\n",
    "        self.output_size = output_size\n",
    "        self.radius_factor = radius_factor\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Assuming img is a PIL Image\n",
    "        # Normalize and preprocess as previously defined\n",
    "        img = func.resize(img, int(min(img.size) / self.radius_factor))\n",
    "        img_tensor = func.to_tensor(img)\n",
    "        mean, std = img_tensor.mean([1, 2]), img_tensor.std([1, 2])\n",
    "        img_normalized = func.normalize(img_tensor, mean.tolist(), std.tolist())\n",
    "        kernel_size = 15\n",
    "        padding = kernel_size // 2\n",
    "        avg_pool = torch.nn.AvgPool2d(kernel_size, stride=1, padding=padding)\n",
    "        local_avg = avg_pool(img_normalized.unsqueeze(0)).squeeze(0)\n",
    "        img_subtracted = img_normalized - local_avg\n",
    "        center_crop_size = int(min(img_subtracted.shape[1:]) * self.radius_factor)\n",
    "        img_cropped = func.center_crop(img_subtracted, [center_crop_size, center_crop_size])\n",
    "\n",
    "        # Apply augmentations\n",
    "        img_resized = func.resize(img_cropped, self.output_size)\n",
    "\n",
    "        return img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10fa6d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:56.555008Z",
     "iopub.status.busy": "2024-05-12T21:22:56.554441Z",
     "iopub.status.idle": "2024-05-12T21:22:56.559284Z",
     "shell.execute_reply": "2024-05-12T21:22:56.558696Z"
    },
    "papermill": {
     "duration": 0.032214,
     "end_time": "2024-05-12T21:22:56.567083",
     "exception": false,
     "start_time": "2024-05-12T21:22:56.534869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_transforms = CustomTransform()\n",
    "\n",
    "train_transforms = v2.Compose([\n",
    "    v2.RandomApply([v2.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.7),\n",
    "    v2.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2)),  # Gaussian blur with random kernel size and sigma\n",
    "    CustomTransform(),\n",
    "    # v2.RandomResizedCrop(CFG.resolution, scale=(0.8, 1.0)),  # Krizhevsky style random cropping\n",
    "    # v2.RandomGrayscale(p=0.2),\n",
    "    v2.RandomHorizontalFlip(),  # Random horizontal flip\n",
    "    v2.RandomVerticalFlip(),  # Random vertical flip\n",
    "    v2.RandomGrayscale(p=0.2),\n",
    "    v2.ToDtype(torch.float32, scale=False),\n",
    "])\n",
    "\n",
    "val_transforms = v2.Compose([\n",
    "    CustomTransform(),\n",
    "    v2.ToDtype(torch.float32, scale=False),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324277b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:56.593996Z",
     "iopub.status.busy": "2024-05-12T21:22:56.593655Z",
     "iopub.status.idle": "2024-05-12T21:22:56.599392Z",
     "shell.execute_reply": "2024-05-12T21:22:56.598859Z"
    },
    "papermill": {
     "duration": 0.02683,
     "end_time": "2024-05-12T21:22:56.600600",
     "exception": false,
     "start_time": "2024-05-12T21:22:56.573770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageTrainDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        folder,\n",
    "        data,\n",
    "        transforms,\n",
    "    ):\n",
    "        self.folder = folder\n",
    "        self.data = data\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        d = self.data.loc[index]\n",
    "        image = Image.open(f\"{self.folder}{d.image}.jpeg\")\n",
    "        image = self.transforms(image)\n",
    "        label = d.level\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8022a0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:56.618073Z",
     "iopub.status.busy": "2024-05-12T21:22:56.617742Z",
     "iopub.status.idle": "2024-05-12T21:22:56.622522Z",
     "shell.execute_reply": "2024-05-12T21:22:56.621914Z"
    },
    "papermill": {
     "duration": 0.024867,
     "end_time": "2024-05-12T21:22:56.632454",
     "exception": false,
     "start_time": "2024-05-12T21:22:56.607587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContrastiveLearningDataset(Dataset):\n",
    "    def __init__(self, folder, data, transform=None):\n",
    "        self.folder = folder\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = f\"{self.folder}{self.data.loc[idx, 'image']}.jpeg\"\n",
    "        label = self.data.loc[idx, 'level']\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            xi = self.transform(image)\n",
    "            xj = self.transform(image)  # Apply the same transform twice\n",
    "        else:\n",
    "            xi = xj = image\n",
    "\n",
    "        return [xi, xj], torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdb52a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:56.647233Z",
     "iopub.status.busy": "2024-05-12T21:22:56.646924Z",
     "iopub.status.idle": "2024-05-12T21:22:58.628752Z",
     "shell.execute_reply": "2024-05-12T21:22:58.628005Z"
    },
    "papermill": {
     "duration": 1.99062,
     "end_time": "2024-05-12T21:22:58.629890",
     "exception": false,
     "start_time": "2024-05-12T21:22:56.639270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize the transformations\n",
    "train_dataset = ContrastiveLearningDataset(TRAIN_DATA_FOLDER, train_data, train_transforms)\n",
    "imgs, label = train_dataset[9]\n",
    "transformed_img_pil = func.to_pil_image(imgs[0])\n",
    "plt.imshow(transformed_img_pil)\n",
    "plt.show()\n",
    "\n",
    "transformed_img_pil_2 = func.to_pil_image(imgs[1])\n",
    "plt.imshow(transformed_img_pil_2)\n",
    "plt.show()\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43589fb",
   "metadata": {
    "id": "OzgB1JpAv3qg",
    "papermill": {
     "duration": 0.03173,
     "end_time": "2024-05-12T21:22:58.695308",
     "exception": false,
     "start_time": "2024-05-12T21:22:58.663578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa22add",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:58.772768Z",
     "iopub.status.busy": "2024-05-12T21:22:58.772445Z",
     "iopub.status.idle": "2024-05-12T21:22:58.966902Z",
     "shell.execute_reply": "2024-05-12T21:22:58.966225Z"
    },
    "id": "WNxSAhBrxJ-G",
    "papermill": {
     "duration": 0.23021,
     "end_time": "2024-05-12T21:22:58.968271",
     "exception": false,
     "start_time": "2024-05-12T21:22:58.738061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score as sklearn_f1\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec2eb57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:59.037470Z",
     "iopub.status.busy": "2024-05-12T21:22:59.036982Z",
     "iopub.status.idle": "2024-05-12T21:22:59.044698Z",
     "shell.execute_reply": "2024-05-12T21:22:59.044214Z"
    },
    "papermill": {
     "duration": 0.045552,
     "end_time": "2024-05-12T21:22:59.045711",
     "exception": false,
     "start_time": "2024-05-12T21:22:59.000159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SupConLoss(nn.Module):\n",
    "    \"\"\"Supervised Contrastive Learning: https://arxiv.org/pdf/2004.11362.pdf.\n",
    "    It also supports the unsupervised contrastive loss in SimCLR\"\"\"\n",
    "    def __init__(self, temperature=0.07, contrast_mode='all',\n",
    "                 base_temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.contrast_mode = contrast_mode\n",
    "        self.base_temperature = base_temperature\n",
    "\n",
    "    def forward(self, features, labels=None, mask=None):\n",
    "        \"\"\"Compute loss for model. If both `labels` and `mask` are None,\n",
    "        it degenerates to SimCLR unsupervised loss:\n",
    "        https://arxiv.org/pdf/2002.05709.pdf\n",
    "\n",
    "        Args:\n",
    "            features: hidden vector of shape [bsz, n_views, ...].\n",
    "            labels: ground truth of shape [bsz].\n",
    "            mask: contrastive mask of shape [bsz, bsz], mask_{i,j}=1 if sample j\n",
    "                has the same class as sample i. Can be asymmetric.\n",
    "        Returns:\n",
    "            A loss scalar.\n",
    "        \"\"\"\n",
    "        device = (torch.device('cuda')\n",
    "                  if features.is_cuda\n",
    "                  else torch.device('cpu'))\n",
    "\n",
    "        if len(features.shape) < 3:\n",
    "            raise ValueError('`features` needs to be [bsz, n_views, ...],'\n",
    "                             'at least 3 dimensions are required')\n",
    "        if len(features.shape) > 3:\n",
    "            features = features.view(features.shape[0], features.shape[1], -1)\n",
    "\n",
    "        batch_size = features.shape[0]\n",
    "        if labels is not None and mask is not None:\n",
    "            raise ValueError('Cannot define both `labels` and `mask`')\n",
    "        elif labels is None and mask is None:\n",
    "            mask = torch.eye(batch_size, dtype=torch.float32).to(device)\n",
    "        elif labels is not None:\n",
    "            labels = labels.contiguous().view(-1, 1)\n",
    "            if labels.shape[0] != batch_size:\n",
    "                raise ValueError('Num of labels does not match num of features')\n",
    "            mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        else:\n",
    "            mask = mask.float().to(device)\n",
    "\n",
    "        contrast_count = features.shape[1]\n",
    "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
    "        if self.contrast_mode == 'one':\n",
    "            anchor_feature = features[:, 0]\n",
    "            anchor_count = 1\n",
    "        elif self.contrast_mode == 'all':\n",
    "            anchor_feature = contrast_feature\n",
    "            anchor_count = contrast_count\n",
    "        else:\n",
    "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
    "\n",
    "        # compute logits\n",
    "        anchor_dot_contrast = torch.div(\n",
    "            torch.matmul(anchor_feature, contrast_feature.T),\n",
    "            self.temperature)\n",
    "        # for numerical stability\n",
    "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
    "        logits = anchor_dot_contrast - logits_max.detach()\n",
    "\n",
    "        # tile mask\n",
    "        mask = mask.repeat(anchor_count, contrast_count)\n",
    "        # mask-out self-contrast cases\n",
    "        logits_mask = torch.scatter(\n",
    "            torch.ones_like(mask),\n",
    "            1,\n",
    "            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
    "            0\n",
    "        )\n",
    "        mask = mask * logits_mask\n",
    "\n",
    "        # compute log_prob\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
    "\n",
    "        # compute mean of log-likelihood over positive\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n",
    "\n",
    "        # loss\n",
    "        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n",
    "        loss = loss.view(anchor_count, batch_size).mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ceb00",
   "metadata": {
    "id": "Zyfw9PLdkpiz",
    "papermill": {
     "duration": 0.018996,
     "end_time": "2024-05-12T21:22:59.083359",
     "exception": false,
     "start_time": "2024-05-12T21:22:59.064363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train and evaluate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec0c627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:59.122652Z",
     "iopub.status.busy": "2024-05-12T21:22:59.122353Z",
     "iopub.status.idle": "2024-05-12T21:22:59.125336Z",
     "shell.execute_reply": "2024-05-12T21:22:59.124877Z"
    },
    "papermill": {
     "duration": 0.023964,
     "end_time": "2024-05-12T21:22:59.126447",
     "exception": false,
     "start_time": "2024-05-12T21:22:59.102483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class style:\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    END = '\\033[0m'\n",
    "    BOLD = '\\033[1m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c3878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:59.275181Z",
     "iopub.status.busy": "2024-05-12T21:22:59.274903Z",
     "iopub.status.idle": "2024-05-12T21:22:59.277975Z",
     "shell.execute_reply": "2024-05-12T21:22:59.277558Z"
    },
    "id": "KKt67LPn9YtB",
    "papermill": {
     "duration": 0.038616,
     "end_time": "2024-05-12T21:22:59.279090",
     "exception": false,
     "start_time": "2024-05-12T21:22:59.240474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937f64ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:22:59.402861Z",
     "iopub.status.busy": "2024-05-12T21:22:59.402580Z",
     "iopub.status.idle": "2024-05-12T21:22:59.407758Z",
     "shell.execute_reply": "2024-05-12T21:22:59.407311Z"
    },
    "id": "nZFniP2hkpi0",
    "papermill": {
     "duration": 0.045161,
     "end_time": "2024-05-12T21:22:59.408782",
     "exception": false,
     "start_time": "2024-05-12T21:22:59.363621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(cfg, train_loader, model, criterion, device, optimizer, scheduler, epoch):  \n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    learning_rate_history = []\n",
    "    total_len = len(train_loader)\n",
    "    tk0 = tqdm(enumerate(train_loader), total=total_len)\n",
    "\n",
    "    for step, (images, labels) in tk0:\n",
    "        images = torch.cat([images[0], images[1]], dim=0)\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        bsz = labels.shape[0]\n",
    "        \n",
    "        # compute loss\n",
    "        features = model(images)\n",
    "        f1, f2 = torch.split(features, [bsz, bsz], dim=0)\n",
    "        features = torch.cat([f1.unsqueeze(1), f2.unsqueeze(1)], dim=1)\n",
    "        \n",
    "        if CFG.cl_method == 'SupCon':\n",
    "            loss = criterion(features, labels)\n",
    "        elif CFG.cl_method == 'SimCLR':\n",
    "            loss = criterion(features)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown contrastive learning method: {CFG.cl_method}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Update learning rate scheduler if present\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "        else:\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        tk0.set_description(f\"Epoch {epoch} training {step+1}/{total_len} [LR {lr:0.6f}] - loss: {train_loss/(step+1):.4f}\")\n",
    "        learning_rate_history.append(lr)\n",
    "\n",
    "    train_loss /= total_len\n",
    "\n",
    "    print(f'Epoch {epoch}: training loss = {train_loss:.4f}')\n",
    "    return train_loss, learning_rate_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7385646",
   "metadata": {
    "id": "qN83vJk4xCA3",
    "papermill": {
     "duration": 0.031485,
     "end_time": "2024-05-12T21:22:59.482585",
     "exception": false,
     "start_time": "2024-05-12T21:22:59.451100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1b8c3d",
   "metadata": {
    "id": "8NyHYtzwZT8h",
    "papermill": {
     "duration": 0.042287,
     "end_time": "2024-05-12T21:22:59.560082",
     "exception": false,
     "start_time": "2024-05-12T21:22:59.517795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Split data\n",
    "\n",
    "The distribution of classes in the training data is not balance so using StratifiedKFold will ensure that the distrubution of positive and negative samples in all folds will match the original distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc83a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_initial_layers(model, freeze_up_to_layer=3):\n",
    "    # The ResNet50 features block is typically named 'layerX' in PyTorch\n",
    "    layer_names = ['conv1', 'bn1', 'layer1', 'layer2', 'layer3', 'layer4']\n",
    "    # Iterate over model children (first level only, adjust as needed)\n",
    "    for name, child in model.named_children():\n",
    "        if name in layer_names[:freeze_up_to_layer]:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "            print(f'Layer {name} has been frozen.')\n",
    "        else:\n",
    "            print(f'Layer {name} is trainable.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21e63a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:23:00.018202Z",
     "iopub.status.busy": "2024-05-12T21:23:00.017896Z",
     "iopub.status.idle": "2024-05-12T21:23:00.021176Z",
     "shell.execute_reply": "2024-05-12T21:23:00.020681Z"
    },
    "papermill": {
     "duration": 0.058473,
     "end_time": "2024-05-12T21:23:00.030393",
     "exception": false,
     "start_time": "2024-05-12T21:22:59.971920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = timm.create_model(CFG.model_name, num_classes=0, pretrained=True)\n",
    "    freeze_initial_layers(model, freeze_up_to_layer=CFG.frozen_layers)\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c8d9d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:23:00.125433Z",
     "iopub.status.busy": "2024-05-12T21:23:00.125148Z",
     "iopub.status.idle": "2024-05-12T21:23:00.129000Z",
     "shell.execute_reply": "2024-05-12T21:23:00.128494Z"
    },
    "papermill": {
     "duration": 0.049105,
     "end_time": "2024-05-12T21:23:00.130091",
     "exception": false,
     "start_time": "2024-05-12T21:23:00.080986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SupConModel(nn.Module):\n",
    "    def __init__(self, encoder, input_dim=2048, output_dim=128):        # assuming either resnet50 or resnet101 is used\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ft = self.encoder(x)\n",
    "        return F.normalize(self.head(ft), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b82c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:23:00.216575Z",
     "iopub.status.busy": "2024-05-12T21:23:00.216284Z",
     "iopub.status.idle": "2024-05-12T21:23:00.394771Z",
     "shell.execute_reply": "2024-05-12T21:23:00.394255Z"
    },
    "papermill": {
     "duration": 0.222447,
     "end_time": "2024-05-12T21:23:00.396230",
     "exception": false,
     "start_time": "2024-05-12T21:23:00.173783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def get_embeddings(model, data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    features = []\n",
    "    targets = []\n",
    "\n",
    "    total_len = len(data_loader)\n",
    "    tk0 = tqdm(enumerate(data_loader), total=total_len)\n",
    "    with torch.no_grad():\n",
    "        for step, (images, labels) in tk0:\n",
    "            images = images.to(device)\n",
    "            target = labels.to(device)\n",
    "\n",
    "            embds = model(images)\n",
    "\n",
    "            features.append(embds.detach().cpu())\n",
    "            targets.append(target.detach().cpu())\n",
    "\n",
    "    features = torch.cat(features, dim=0)\n",
    "    targets = torch.cat(targets, dim=0)\n",
    "    \n",
    "    # store the embeddings for future use\n",
    "    torch.save(features, os.path.join(wandb.run.dir, f\"embeddings.pth\"))\n",
    "    torch.save(targets, os.path.join(wandb.run.dir, f\"targets.pth\"))\n",
    "\n",
    "    return features, targets\n",
    "\n",
    "\n",
    "def plot_tsne(embeddings, labels, name='tsne.png'):\n",
    "    # Apply t-SNE to the embeddings\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "    tsne_results = tsne.fit_transform(embeddings.numpy())\n",
    "\n",
    "    # Define the number of unique labels/classes\n",
    "    num_classes = len(np.unique(labels.numpy()))\n",
    "    # Create a custom color map with specific color transitions\n",
    "    colors = ['blue', 'green', 'yellow', 'orange', 'red']\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"Custom\", colors, N=num_classes)\n",
    "\n",
    "    # Create a boundary norm with boundaries and colors\n",
    "    norm = mcolors.BoundaryNorm(np.arange(-0.5, num_classes + 0.5, 1), cmap.N)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=labels, cmap=cmap, norm=norm, alpha=0.5)\n",
    "    colorbar = plt.colorbar(scatter, ticks=np.arange(num_classes))\n",
    "    colorbar.set_label('Severity Level')\n",
    "    colorbar.set_ticklabels(np.arange(num_classes))  # Set discrete labels if needed\n",
    "    plt.title('t-SNE of Image Embeddings with Discrete Severity Levels')\n",
    "    plt.xlabel('t-SNE Axis 1')\n",
    "    plt.ylabel('t-SNE Axis 2')\n",
    "    fg = wandb.Image(fig)\n",
    "    wandb.log({\"t-SNE\": fg})\n",
    "    plt.savefig(os.path.join(wandb.run.dir, name), dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750c7219",
   "metadata": {
    "id": "rF9BFqS8AXBY",
    "papermill": {
     "duration": 0.055111,
     "end_time": "2024-05-12T21:23:00.507023",
     "exception": false,
     "start_time": "2024-05-12T21:23:00.451912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9df388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T21:23:00.684316Z",
     "iopub.status.busy": "2024-05-12T21:23:00.684034Z",
     "iopub.status.idle": "2024-05-12T21:32:37.579724Z",
     "shell.execute_reply": "2024-05-12T21:32:37.578438Z"
    },
    "papermill": {
     "duration": 576.942207,
     "end_time": "2024-05-12T21:32:37.580821",
     "exception": true,
     "start_time": "2024-05-12T21:23:00.638614",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed_everything(CFG.seed)\n",
    "\n",
    "# # Prepare datasets and data loaders\n",
    "# fold_train_data = train_data[train_data[\"fold\"] != FOLD].reset_index(drop=True)\n",
    "# fold_valid_data = train_data[train_data[\"fold\"] == FOLD].reset_index(drop=True)\n",
    "\n",
    "train_dataset = ContrastiveLearningDataset(TRAIN_DATA_FOLDER, train_data, transform=train_transforms)\n",
    "# valid_dataset = ImageTrainDataset(TRAIN_DATA_FOLDER, fold_valid_data, transforms=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CFG.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=CFG.workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "# Prepare model, optimizer, and scheduler\n",
    "resnet = create_model()\n",
    "model = SupConModel(resnet).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=1e-6, T_max =CFG.epochs * len(train_loader))\n",
    "\n",
    "criterion = SupConLoss()\n",
    "\n",
    "for epoch in range(CFG.epochs):\n",
    "    train_loss, train_lr = train_epoch(CFG, train_loader, model, criterion, device, optimizer, scheduler, epoch)\n",
    "    scheduler.step()  # Update the learning rate scheduler at the end of each epoch\n",
    "\n",
    "    if (epoch+1) % 3 == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(wandb.run.dir, f'ckpt_epoch_{epoch}.pth'))\n",
    "\n",
    "        # plot a tsne plot of all the images using embeddings from the model\n",
    "        full_dataset = ImageTrainDataset(TRAIN_DATA_FOLDER, train_data, transforms=val_transforms)\n",
    "        loader = DataLoader(\n",
    "            full_dataset,\n",
    "            batch_size=CFG.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=CFG.workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "        features, targets = get_embeddings(model, loader)\n",
    "        plot_tsne(features, targets, f'tsne_{epoch}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31170505",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4568125,
     "sourceId": 7801430,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4568781,
     "sourceId": 7877494,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 602.688272,
   "end_time": "2024-05-12T21:32:41.248059",
   "environment_variables": {},
   "exception": true,
   "input_path": "simclr.ipynb",
   "output_path": "simclr.ipynb",
   "parameters": {},
   "start_time": "2024-05-12T21:22:38.559787",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08d2c86ce4ab4b9e813473170145d4af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96fb1b36ead648c4a4ebebb74c9fcf2c",
      "placeholder": "​",
      "style": "IPY_MODEL_af10206931434c6fbfde31af25affbfa",
      "value": "model.safetensors: 100%"
     }
    },
    "103798aed0c64914b55a691a4d22253e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4420cb88a6a74540a671a529e7320589",
      "placeholder": "​",
      "style": "IPY_MODEL_6b7cb0c6580d4caba2c4f8385749a145",
      "value": " 124M/124M [00:00&lt;00:00, 384MB/s]"
     }
    },
    "2831af4d288b45b688ba9b5992dce3f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3763df1b6564f319afc8d67073af72f",
      "max": 124450218,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a4c3f492a9b946a0b72df7ea6bb188a9",
      "value": 124450218
     }
    },
    "4420cb88a6a74540a671a529e7320589": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b7cb0c6580d4caba2c4f8385749a145": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "87901707be784b03998e8b8093255ea6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96fb1b36ead648c4a4ebebb74c9fcf2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3763df1b6564f319afc8d67073af72f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4c3f492a9b946a0b72df7ea6bb188a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "af10206931434c6fbfde31af25affbfa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b53d0ba4ae3e496092fdf021cb4097aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_08d2c86ce4ab4b9e813473170145d4af",
       "IPY_MODEL_2831af4d288b45b688ba9b5992dce3f4",
       "IPY_MODEL_103798aed0c64914b55a691a4d22253e"
      ],
      "layout": "IPY_MODEL_87901707be784b03998e8b8093255ea6"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
